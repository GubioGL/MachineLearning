{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch as tc\n",
    "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v= Constante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq_movimento(x_0,v_,t_): \n",
    "    return  x_0 + v_*t_\n",
    "\n",
    "t = np.linspace(0,10)  \n",
    "\n",
    "plt.plot(t,eq_movimento(x_0=0,v_=2,t_=t),\".\")\n",
    "plt.plot(t,eq_movimento(x_0=0,v_=1,t_=t),\".\")\n",
    "plt.plot(t,eq_movimento(x_0=1,v_=1,t_=t),\".\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,10).reshape((-1, 1))  \n",
    "y = eq_movimento(x_0=0,v_=2,t_=t)\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(t,y)# FITANDO \n",
    "print(\"a: \",reg.coef_)\n",
    "print(\"b: \",reg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "RT = DecisionTreeRegressor(criterion = \"squared_error\")\n",
    "RT.fit(t,y)# FITANDO \n",
    "\n",
    "t_tes = np.linspace(0,10).reshape((-1, 1))  \n",
    "predição = RT.predict(t_tes)\n",
    "\n",
    "plt.plot(t,y,\"-\")\n",
    "plt.plot(t_tes,predição,\".\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressao(nn.Module):\n",
    "    def __init__(self,neuronio):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(1,neuronio)\n",
    "        self.layer_3 = nn.Linear(neuronio,1)\n",
    "        self.A_layer = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.A_layer(self.layer_1(x))\n",
    "        x = self.A_layer(self.layer_3(x))\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_parametro(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss_parametro, self).__init__()\n",
    "    def forward(self, inputs, targets,outputs):\n",
    "        # mudar de [N,1] para [N]\n",
    "        # função 1° grau: x- x0 -vt = 0\n",
    "        funcao_1_grau = targets - targets[0] - outputs*inputs\n",
    "        loss_solution = tc.mean( abs(funcao_1_grau) )\n",
    "        # podemos impor que independe do input o parametro deve ser igual  \n",
    "        # v_medio = output[:,1].mean()\n",
    "        # loss_const = tc.mean((output[:,1] - v_medio) ** 2)\n",
    "        return loss_solution\n",
    "    \n",
    "class Loss_edo(nn.Module):\n",
    "    def __init__(self,rede_neural,velocidade):\n",
    "        super(Loss_edo, self).__init__()\n",
    "        self.rede = rede_neural\n",
    "        self.v = velocidade\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        output ,derivadas = tc.autograd.functional.jvp(self.rede ,inputs ,v=tc.ones(len(inputs),1),create_graph=True) # v é um vetor unitario para retorna apenas o jacobiano\n",
    "        # condição inicial x(0)\n",
    "        loss_ic = (output[0] - targets[0])**2\n",
    "        \n",
    "        # dividido pela tamanho do dados de entrada\n",
    "        loss_ic = loss_ic/len(inputs)\n",
    "        # Derivada da função em relação a entrada \n",
    "        # edo : dx/dt = v\n",
    "        # estamos usando [1:] para escluir a condição inicial\n",
    "        loss_edo = tc.mean( (derivadas[1:] - self.v )**2 )\n",
    "\n",
    "        return loss_ic + loss_edo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendendo a função com a edo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq_movimento(x_0,v_,t_): \n",
    "    return  x_0 + v_*t_\n",
    "\n",
    "# Criando os dados de treino\n",
    "x_train = tc.linspace(0,10,50).reshape(50,1)\n",
    "y_train =  eq_movimento(x_0=0,v_=1,t_=x_train)\n",
    "\n",
    "rede1 = Regressao(20) # rede da função\n",
    "opt1 = tc.optim.Adam(params=rede1.parameters(),lr=0.01)  # rede da função\n",
    "loss_fn1  = Loss_edo(rede1,velocidade=1)\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    rede1.train()\n",
    "    loss = loss_fn1(x_train, y_train)\n",
    "    opt1.zero_grad()\n",
    "    loss.backward()\n",
    "    opt1.step() \n",
    "\n",
    "#rede 1 é a função\n",
    "loss_fn = nn.MSELoss()\n",
    "rede1.eval()\n",
    "with tc.inference_mode():\n",
    "    prediçao = rede1(x_train)\n",
    "    loss = loss_fn( prediçao,y_train)\n",
    "    print(f\"| Train Loss: {loss} |\")\n",
    "    \n",
    "plt.plot(x_train,y_train,\"k-\" ,label=\"teorico\")\n",
    "plt.plot(x_train, prediçao,\".\",label=\"predição\" )\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendendo o valor da constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq_movimento(x_0,v_,t_): \n",
    "    return  x_0 + v_*t_\n",
    "\n",
    "# Criando os dados de treino\n",
    "x_train = tc.linspace(0,10,20).reshape(20,1)\n",
    "y_train =  eq_movimento(x_0=0,v_=1,t_=x_train)\n",
    "\n",
    "\n",
    "rede2 = Regressao(10) # rede dos parametros \n",
    "opt2 = tc.optim.Adam(params=rede2.parameters(),lr=0.01) # rede dos parametros \n",
    "loss_fn2  = Loss_parametro()\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    rede2.train()\n",
    "    y_preds = rede2(x_train)\n",
    "    loss = loss_fn2(inputs=x_train,targets=y_train, outputs=y_preds)\n",
    "    opt2.zero_grad()\n",
    "    loss.backward()\n",
    "    opt2.step() \n",
    "    \n",
    "    \n",
    "    rede1.train()\n",
    "    loss = loss_fn1(x_train, y_train)\n",
    "    opt1.zero_grad()\n",
    "    loss.backward()\n",
    "    opt1.step() \n",
    "\n",
    "#rede 2 é a parametro\n",
    "loss_fn = nn.MSELoss()\n",
    "rede2.eval()\n",
    "with tc.inference_mode():\n",
    "    prediçao = rede2(x_train)\n",
    "    loss = loss_fn(y_train[0] + prediçao*x_train,y_train)\n",
    "    print(f\"| Train Loss: {loss} |\")\n",
    "    print(prediçao[:5])\n",
    "plt.plot(x_train,y_train,\"k-\" ,label=\"teorico\")\n",
    "plt.plot(x_train,y_train[0] + prediçao*x_train,\".\",label=\"predição\" )\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a =Constante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq_movimento(x_0,v_,a_,t_):\n",
    "    return  x_0 + v_*t_ + a_*t_**2/2\n",
    "\n",
    "t = np.linspace(0,1.4).reshape((-1, 1))    \n",
    "y = eq_movimento(x_0=10,v_=0,a_=-9.81,t_=t)\n",
    "plt.plot(t,y,\".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(t,y)# FITANDO \n",
    "print(\"a: \",reg.coef_)\n",
    "print(\"b: \",reg.intercept_)\n",
    "\n",
    "plt.plot(t,y,\".\")\n",
    "plt.plot(t,reg.intercept_[0] + reg.coef_[0][0]*t,\".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "RT = DecisionTreeRegressor(criterion = \"squared_error\")\n",
    "RT.fit(t,y)# FITANDO \n",
    "\n",
    "\n",
    "predição = RT.predict(t)\n",
    "\n",
    "plt.plot(t,y,\"-\")\n",
    "plt.plot(t,predição,\".\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressaõ polinomia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "t_poly = poly.fit_transform(t)\n",
    "\n",
    "R = linear_model.LinearRegression()\n",
    "train_y_ = R.fit(t_poly, y)\n",
    "# The coefficients\n",
    "print ('Coefficients: ', R.coef_)\n",
    "print ('b: ',R.intercept_)\n",
    "\n",
    "predição = R.intercept_[0]+ R.coef_[0][1]*t+ R.coef_[0][2]*t**2\n",
    "plt.plot(t,y,\"-\")\n",
    "plt.plot(t,predição,\".\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-Rede neural "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressao(nn.Module):\n",
    "    def __init__(self,neuronio):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(1,neuronio)\n",
    "        self.layer_2 = nn.Linear(neuronio,neuronio)\n",
    "        self.layer_3 = nn.Linear(neuronio,1)\n",
    "        self.A_layer = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.A_layer(self.layer_1(x))\n",
    "        x = self.A_layer(self.layer_2(x))\n",
    "        x = self.layer_3(x)\n",
    "        return x\n",
    "    \n",
    "class loss_pinn1(nn.Module):\n",
    "    \"\"\"_summary_\n",
    "    Essa loss utiliza a saida da rede neural como uma função quedeve ser solução de uma equação.\n",
    "    Nesse caso é a solução da edo de 2° ordem.\n",
    "    \n",
    "            d^2 x/dt^2 = a\n",
    "    \n",
    "    Será fornecido  o valor de a, condição inicial da posição e velocidade.\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self, t, y_true, aceleracao, velocity=None):\n",
    "        super(loss_pinn1,self).__init__()\n",
    "        self.t_ = t\n",
    "        self.v_ = velocity\n",
    "        self.a_ = aceleracao\n",
    "        self.y_true_ = y_true\n",
    "\n",
    "    def forward(self,y_pred):\n",
    "        dydt = tc.autograd.grad(y_pred, self.t_, grad_outputs=tc.ones_like(y_pred), create_graph=True)[0]\n",
    "        d2ydt2 = tc.autograd.grad(dydt, self.t_, grad_outputs=tc.ones_like(y_pred), create_graph=True)[0]\n",
    "        \n",
    "        # Condiçao incial da posição\n",
    "        loss_ic_x0 = (y_pred[0] -self.y_true_[0] )**2\n",
    "        # Condiçao incial da velocidade\n",
    "        loss_ic_v0 = (dydt[0] -self.v_ )**2\n",
    "        \n",
    "        # Edo d^2 x/dt^2 = a\n",
    "        loss_edo_xx = (d2ydt2 - self.a_)**2/len(self.t_)\n",
    "        # Edo dx/dx = a\n",
    "        #loss_edo_x = (dydt - self.a_)**2\n",
    "        return tc.sum(loss_edo_xx) + loss_ic_x0 + loss_ic_v0\n",
    "    \n",
    "class loss_pinn2(nn.Module):\n",
    "    \"\"\"_summary_:\n",
    "    Essa loss utiliza a saida da rede neural como um parâmetro da solução de uma equação.\n",
    "    Nesse caso é a solução da edo de 2° ordem \n",
    "    \n",
    "    -->>>  d^2x/dt^2 = a\n",
    "    -->>> y(t) = x(0) + v(0)*t + at**2/2\n",
    "    \n",
    "    Será fornecido  o valor de cada instante de tempo , valor da posição e velocidade em t = 0.\n",
    "    \"\"\"\n",
    "    def __init__(self,x_0,v_0, y_,t_):\n",
    "        super().__init__()\n",
    "        self.x0 = x_0\n",
    "        self.v0 = v_0\n",
    "        self.true_output = y_\n",
    "        self.tempo = t_\n",
    "        \n",
    "    def forward(self, outputs_p,output_f=0,output_f2 = 0):\n",
    "        # talvez adicionar a derivada \n",
    "        # y  =  x_0 + v_*t_ + a_*t_**2/2\n",
    "        solution = (self.true_output - self.x0 -self.v0*self.tempo - outputs_p*self.tempo**2/2)**2\n",
    "        solution_data =  (self.true_output- output_f)**2\n",
    "        return tc.mean(solution) + tc.mean(solution_data)*output_f2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eq_movimento(x_0,v_,a_,t_):\n",
    "    return  x_0 + v_*t_ + a_*t_**2/2\n",
    "device ='cuda'\n",
    "N=50\n",
    "# Criando os dados de treino\n",
    "x_train = tc.linspace(0,1.4,N,requires_grad=True,device=device).reshape(N,1)\n",
    "y_train =  eq_movimento(x_0=10,v_=0,a_=-9.81,t_=x_train)\n",
    "\n",
    "# Visualizando os dados de treino\n",
    "\n",
    "plt.plot(x_train.cpu().detach().numpy(),y_train.cpu().detach().numpy(),\"k.\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendendo a função com os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regressao(neuronio=20).to(device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = tc.optim.Adam(params=model.parameters(),lr=0.01)\n",
    "\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_preds = model(x_train)\n",
    "    loss = loss_fn(y_preds, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with tc.inference_mode():\n",
    "    y_preds_test = model(x_train)\n",
    "    loss = loss_fn(y_preds_test,y_train)\n",
    "    print(f\"| Train Loss: {loss} | \")\n",
    "\n",
    "plt.plot(x_train.cpu().detach().numpy(),y_train.cpu().detach().numpy(),\"-\")\n",
    "plt.plot(x_train.cpu().detach().numpy(),y_preds_test.cpu().detach().numpy(),\"k.\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aprendendo o parametro da equação(Aceleração)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regressao(neuronio=5,output=1,activation=\"tanh\",h_layer=True).to(device=device)  \n",
    "loss_fn = loss_pinn2(x_0=10,v_0=0,y_= y_train,t_=x_train)\n",
    "optimizer = tc.optim.Adam(params=model.parameters(),lr=0.01)\n",
    "\n",
    "LOSS = []\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_preds = model(x_train)\n",
    "    loss = loss_fn(y_preds[:])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    LOSS.append(loss.cpu().detach().numpy())\n",
    "\n",
    "model.eval()\n",
    "with tc.inference_mode():\n",
    "    y_preds = model(x_train)\n",
    "    loss = loss_fn(y_preds[0,0],y_preds[:,0],1)\n",
    "    print(f\"| Train Loss: {loss} | \")\n",
    "    \n",
    "x = x_train.cpu().detach().numpy()\n",
    "y = y_train.cpu().detach().numpy()\n",
    "\n",
    "aceleracao = y_preds[0].cpu().detach().numpy()\n",
    "#funcao = y_preds[:,1].cpu().detach().numpy()\n",
    "y_predic = 10 +aceleracao*x**2/2\n",
    "\n",
    "plt.plot(x,y,\"k-\",label=\"teorico\")\n",
    "plt.plot(x,y_predic,\"r--\", label=f\"a:{np.round(aceleracao,decimals=2)}\" )\n",
    "#plt.plot(x,funcao)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(LOSS);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regressao(neuronio=15).to(device)\n",
    "loss_fn = loss_pinn1(x_train, y_train, aceleracao=-9.81, velocity=0.0)\n",
    "optimizer = tc.optim.Adam(params=model.parameters(),lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "  model.train()\n",
    "  y_pred  = model(x_train)\n",
    "  loss    = loss_fn(y_pred)\n",
    "  \n",
    "  optimizer.zero_grad()\n",
    "  loss.backward(retain_graph=True)\n",
    "  optimizer.step()\n",
    "\n",
    "x = x_train.cpu().detach().numpy()\n",
    "y = y_train.cpu().detach().numpy()\n",
    "\n",
    "y_pred = model(x_train)\n",
    "y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].plot(x,y,\"k-\",label=\"teorico\")\n",
    "ax[0].plot(x,y_pred,\"r--\",label=\"rede\")\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel(\"y(t)\")\n",
    "ax[0].set_xlabel(\"t (time)\")\n",
    "ax[1].plot(LOSS)\n",
    "ax[1].set_xlabel(\"epochs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forma de derivar :\n",
    "#model = Regressao(neuronio=10)\n",
    "#derivada = [tc.autograd.functional.hessian(model,i)[0] for i in x_train] # Fuciona\n",
    "#y_preds,derivada =tc.autograd.functional.hvp(model ,x_train[0],create_graph=True,strict=True)  # fuciona\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
